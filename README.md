Dear sir,

Vishal Jindal by this side, I had called you on Sunday evening stating that I am having examinations and therefore I have been only able to scrape the data and put it in MongoDB. I am here for experience sir and it would be great if I can join as an intern for any junior role. The website can only be scraped till 100 pages after which there is no link. Because of which API call is the only option to scrape the data after 100 pages in the website. I have provided the following files in the link:

1) Readme File
2) Python file for Scraping data for all the cities which was asked (3 files - 1 with code for web scraping bangalore having offline database, code for web scraping bangalore having online database and 1 with all cities having online database ) 
3) Python file Scraping Bangalore properties ( Have showed it just as it takes less time to analyze the data and code. )
4) Text file containing MongoDB links
5) Video 1 part 1 to 5 - Showing the entire process and scraped data 
6) Video 2 - Showing MongoDB
7) Properties.csv file - containing data of properties in CSV format

I have also provided my contact number and mail if any explanation is needed.
Phone: 9081315782
Email:vishal.jindal@bca.christuniversity.in


Thank you sir

Yours Sincerely
Vishal Jindal
